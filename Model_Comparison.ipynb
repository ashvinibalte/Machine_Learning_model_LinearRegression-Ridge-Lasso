{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98HN3WB3DxQ",
        "outputId": "55341ba0-4f93-4d75-8f52-486144393231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/gdrive/MyDrive/Colab Notebooks/BigDataAssignment4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wCG5tKM3IwK",
        "outputId": "81dc6fba-d7d0-418c-966b-24f6f64e3c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/BigDataAssignment4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4OZ6OoFYA1"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXfQK0uXFYA5",
        "outputId": "bdce0656-cb3e-430a-90f2-be620d191461",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 0         x         y\n",
            "0            0  0.000000  0.442580\n",
            "1            1  0.052632  0.750379\n",
            "2            2  0.105263  0.982555\n",
            "3            3  0.157895  0.853643\n",
            "4            4  0.210526  1.141193\n",
            "5            5  0.263158  0.831381\n",
            "6            6  0.315789  1.147227\n",
            "7            7  0.368421  1.010907\n",
            "8            8  0.421053  0.664553\n",
            "9            9  0.473684  0.334169\n",
            "10          10  0.526316 -0.058656\n",
            "11          11  0.578947 -0.589828\n",
            "12          12  0.631579 -0.569363\n",
            "13          13  0.684211 -0.869054\n",
            "14          14  0.736842 -1.166119\n",
            "15          15  0.789474 -1.304733\n",
            "16          16  0.842105 -0.830502\n",
            "17          17  0.894737 -0.538124\n",
            "18          18  0.947368 -0.485276\n",
            "19          19  1.000000 -0.167024\n"
          ]
        }
      ],
      "source": [
        "# read traning data\n",
        "pd_train = pd.read_csv(\"exercise_3_training.csv\")\n",
        "\n",
        "# print the dataframe\n",
        "print(pd_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuoa9vOxFYA6"
      },
      "outputs": [],
      "source": [
        "# create the input and output attributes\n",
        "inp_attr = pd_train['x'].values.reshape(-1, 1)\n",
        "\n",
        "# generate the nonlinear features\n",
        "poly_order = 20\n",
        "poly = PolynomialFeatures(poly_order,include_bias=False)\n",
        "inp_feat = poly.fit_transform(inp_attr)\n",
        "#print(inp_feat)\n",
        "out_attr = pd_train['y'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkf-M-4FFYA7",
        "outputId": "bf78391b-ff87-4971-9579-e6fbabf020b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "inp_feat.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCPD1VPIFYA7",
        "outputId": "9f7d661e-e544-4c29-9bb4-6f030b908991",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coef =  [-0.59024585 -1.67949412 -1.22932661 -0.57986637 -0.06644834  0.26968903\n",
            "  0.45988645  0.54465164  0.55777382  0.52421925  0.46154418  0.38179648\n",
            "  0.29311957  0.20094521  0.10883834  0.01908377 -0.06690923 -0.14832819\n",
            " -0.22476509 -0.29608326]\n"
          ]
        }
      ],
      "source": [
        "# L2 penalty - vary alpha and observe the magnitude of the coeff and the errors\n",
        "# Note that regularization coefficient - alpha=lambda (in the lecture)\n",
        "# alpha = 0.0\n",
        "# alpha = 0.1\n",
        "# alpha = 100\n",
        "\n",
        "l2 = Ridge(alpha=0.1)\n",
        "l2.fit(inp_feat, out_attr)\n",
        "print('coef = ', l2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mk2_6e4FYA7"
      },
      "outputs": [],
      "source": [
        "# read testing data\n",
        "pd_test = pd.read_csv(\"exercise_3_training.csv\")\n",
        "\n",
        "# create the input and output attributes\n",
        "test_inp_attr = pd_test['x'].values.reshape(-1, 1)\n",
        "\n",
        "# generate the nonlinear features\n",
        "test_inp_feat = poly.fit_transform(test_inp_attr)\n",
        "test_out_attr = pd_test['y'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ3yYfLPFYA8",
        "outputId": "1c874240-6a16-4998-834e-fc785852aaa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 - MSE train =  0.0990607512903737\n",
            "L2 - MSE test =  0.0990607512903737\n"
          ]
        }
      ],
      "source": [
        "# L2 - model performance\n",
        "l2_train_pred = l2.predict(inp_feat)\n",
        "print('L2 - MSE train = ', mean_squared_error(l2_train_pred,out_attr))\n",
        "\n",
        "l2_test_pred = l2.predict(test_inp_feat)\n",
        "print('L2 - MSE test = ', mean_squared_error(l2_test_pred,test_out_attr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.Replace the line l2=Ridge(alpha=0.1) with l2=Lasso(alpha=0.1). Execute the notebook for alpha=0.1, and alpha=100.**"
      ],
      "metadata": {
        "id": "4NY8sJEVXHJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "752ec375-9651-4e30-fe5c-e43b5be30582",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MZdCe7mYDCv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model parameters/coefficients =  [-1.03352367 -0.         -0.         -0.         -0.         -0.\n",
            " -0.         -0.         -0.         -0.         -0.         -0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.        ]\n"
          ]
        }
      ],
      "source": [
        "# L2 penalty - vary alpha and observe the magnitude of the coeff and the errors\n",
        "# Note that regularization coefficient - alpha=lambda (in the lecture)\n",
        "# alpha = 0.0\n",
        "# alpha = 0.1\n",
        "# alpha = 100\n",
        "\n",
        "l2=Lasso(alpha=0.1) # replacing l2=Lasso(alpha=0.1)\n",
        "l2.fit(inp_feat, out_attr)\n",
        "print('model parameters/coefficients = ', l2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQLnm7IvYDCw"
      },
      "outputs": [],
      "source": [
        "# read testing data\n",
        "pd_test = pd.read_csv(\"exercise_3_training.csv\")\n",
        "\n",
        "# create the input and output attributes\n",
        "test_inp_attr = pd_test['x'].values.reshape(-1, 1)\n",
        "\n",
        "# generate the nonlinear features\n",
        "test_inp_feat = poly.fit_transform(test_inp_attr)\n",
        "test_out_attr = pd_test['y'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "e91d9411-258c-4760-ce7b-38164dd55dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpU_nnjJYDCx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 - MSE train =  0.34234948898867806\n",
            "L2 - MSE test =  0.34234948898867806\n"
          ]
        }
      ],
      "source": [
        "# L2 - model performance\n",
        "l2_train_pred = l2.predict(inp_feat)\n",
        "print('L2 - MSE train = ', mean_squared_error(l2_train_pred,out_attr))\n",
        "\n",
        "l2_test_pred = l2.predict(test_inp_feat)\n",
        "print('L2 - MSE test = ', mean_squared_error(l2_test_pred,test_out_attr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **alpha=100.**"
      ],
      "metadata": {
        "id": "NYa--nGoYlqB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "36dc28b5-6cd6-47d5-8cbe-f82e4f966891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMjvjqtcY0Ew"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model parameters/coefficients =  [-0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n"
          ]
        }
      ],
      "source": [
        "# L2 penalty - vary alpha and observe the magnitude of the coeff and the errors\n",
        "# Note that regularization coefficient - alpha=lambda (in the lecture)\n",
        "# alpha = 0.0\n",
        "#alpha = 0.1\n",
        "#alpha = 100\n",
        "\n",
        "l2=Lasso(alpha=100) # replacing l2=Lasso(alpha=100)\n",
        "l2.fit(inp_feat, out_attr)\n",
        "print('model parameters/coefficients = ', l2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQc_J48UY0E4"
      },
      "outputs": [],
      "source": [
        "# read testing data\n",
        "pd_test = pd.read_csv(\"exercise_3_training.csv\")\n",
        "\n",
        "# create the input and output attributes\n",
        "test_inp_attr = pd_test['x'].values.reshape(-1, 1)\n",
        "\n",
        "# generate the nonlinear features\n",
        "test_inp_feat = poly.fit_transform(test_inp_attr)\n",
        "test_out_attr = pd_test['y'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "040db368-271f-42e8-ee57-7367498e9e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb0_-6VWY0E4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 - MSE train =  0.647438408969314\n",
            "L2 - MSE test =  0.647438408969314\n"
          ]
        }
      ],
      "source": [
        "# L2 - model performance\n",
        "l2_train_pred = l2.predict(inp_feat)\n",
        "print('L2 - MSE train = ', mean_squared_error(l2_train_pred,out_attr))\n",
        "\n",
        "l2_test_pred = l2.predict(test_inp_feat)\n",
        "print('L2 - MSE test = ', mean_squared_error(l2_test_pred,test_out_attr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Add a new cell at the end of the notebook and add your answers to the following questions as comments. **\n",
        "\n",
        "**2.1. What happens with the model parameters/coefficients when alpha=0.1?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1.    Lasso regression [ Least Absolute Shrinkage and Selection Operator],in cost\n",
        "function it adds the penalty term. This term is calculated by absolute sum of the coefficients\n",
        "\n",
        "\n",
        "2.     After applying L2=Ridge(alpha=0.1). The value of  model parameters/coefficients is: [-0.59024585 -1.67949412 -1.22932661 -0.57986637 -0.06644834  0.26968903 0.45988645  0.54465164  0.55777382  0.52421925  0.46154418  0.38179648 0.29311957  0.20094521  0.10883834  0.01908377 -0.06690923 -0.14832819 -0.22476509 -0.29608326]\n",
        "\n",
        "\n",
        "3.     Also after applying the l2=Lasso(alpha=0.1) The value of  model parameters/coefficients is:   [-1.03352367 -0.         -0.         -0.         -0.         -0.  -0.         -0.         -0.         -0.         -0.         -0.   0.          0.          0.          0.          0.          0.  0.          0.   ]\n",
        "\n",
        "\n",
        "4.     We clearly observe that after applying Lasso(alpha=0.1) value of model parameters/coefficients are changing the 1st parameter value is changing from [-0.59024585 ] to [-1.03352367], whereas remaining parameter value are changes from some value to the 0 (zero).\n",
        "**2.2. What happens with the model parameters when alpha=100? Explain why is this happening.**\n",
        "\n",
        "**Answer:**\n",
        "1.  You can see that, as we increase the value of alpha, the magnitude of the coefficients decreases, where the coefficient value reaches zero.\n",
        "2.   When alpha value is high there is a bigger penalty and for that reason the magnitude of coefficients are reduced.\n",
        "3.    So, when alpha =100, the lasso regression  gives the null model in which all coefficient estimates equal zero\n",
        "**2.3. How does MSE compares between alpha=0.1 and alpha=100? Explain which model you prefer.**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1.   For our data when alpha = 0.1, then the lasso regression  gives the least squares fit, and when alpha becomes very large i.e alpha=100, the lasso gives the null model in which all coefficient estimates equal zero.\n",
        "\n",
        "2.   MSE when alpha=0.1\n",
        "\n",
        "     L2 - MSE train =  0.34234948898867806\n",
        "     \n",
        "     L2 - MSE test =  0.34234948898867806L2\n",
        "\n",
        "3.   MSE when alpha=100\n",
        "\n",
        "     L2 - MSE train =  0.647438408969314\n",
        "\n",
        "     L2 - MSE test =  0.647438408969314\n",
        "\n",
        "4.   We need the alpha value that minimizes the MSE because it will help to overcome overfitting.\n",
        "\n",
        "5.    In this case the alpha=0.1 value gives the minimum value of Mean Square Error for training as well as test data. So, we select the alpha=0.1 to avoid overfitting.\n"
      ],
      "metadata": {
        "id": "lXWZ7MS9YTfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Now replace the same line with l2=LinearRegression(). Execute the entire notebook.**"
      ],
      "metadata": {
        "id": "N8Gvf0m8ZQOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "93f1d761-f890-4c36-a59b-41f6bccde43f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xai83mOCZhFq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model parameters/coefficients =  [-2.60429857e+04  1.66021982e+06 -4.55463186e+07  7.25884218e+08\n",
            " -7.60880085e+09  5.60762719e+10 -3.02274990e+11  1.21971777e+12\n",
            " -3.72536198e+12  8.60617788e+12 -1.47811533e+13  1.79179180e+13\n",
            " -1.28403376e+13 -3.02767157e+11  1.35419924e+13 -1.81116496e+13\n",
            "  1.34368586e+13 -6.14438987e+12  1.62920191e+12 -1.93081499e+11]\n"
          ]
        }
      ],
      "source": [
        "# L2 penalty - vary alpha and observe the magnitude of the coeff and the errors\n",
        "# Note that regularization coefficient - alpha=lambda (in the lecture)\n",
        "# alpha = 0.0\n",
        "#alpha = 0.1\n",
        "#alpha = 100\n",
        "\n",
        "l2=LinearRegression() # replace with l2=LinearRegression()\n",
        "l2.fit(inp_feat, out_attr)\n",
        "print('model parameters/coefficients = ', l2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4C_49sLZhFr"
      },
      "outputs": [],
      "source": [
        "# read testing data\n",
        "pd_test = pd.read_csv(\"exercise_3_training.csv\")\n",
        "\n",
        "# create the input and output attributes\n",
        "test_inp_attr = pd_test['x'].values.reshape(-1, 1)\n",
        "\n",
        "# generate the nonlinear features\n",
        "test_inp_feat = poly.fit_transform(test_inp_attr)\n",
        "test_out_attr = pd_test['y'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "ffca1c4f-0300-4167-b8a4-c2f526759049",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0KctOH4ZhFs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 - MSE train =  8.037539242127623e-07\n",
            "L2 - MSE test =  8.037539242127623e-07\n"
          ]
        }
      ],
      "source": [
        "# L2 - model performance\n",
        "l2_train_pred = l2.predict(inp_feat)\n",
        "print('L2 - MSE train = ', mean_squared_error(l2_train_pred,out_attr))\n",
        "\n",
        "l2_test_pred = l2.predict(test_inp_feat)\n",
        "print('L2 - MSE test = ', mean_squared_error(l2_test_pred,test_out_attr))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Add another new cell at the end of the notebook and add your answers to the following questions as comments.**\n",
        "\n",
        "**4.1. What can you say about the magnitude of the model parameters?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1.   In the Linear Regression model,The magnitude of the  model parameters coefficient  shows the strength of the association.\n",
        "\n",
        "2.  Also the sign i.e +ve and -ve indicate the direction of association\n",
        "The coefficient value  1.79179180e+13 indicated the positive association between two variables, whereas a coefficient value -2.60429857e+04 indicated a weak negative association.\n",
        "\n",
        "3. In addition to that , the coefficient value close to zero suggests no linear association between two variables.\n",
        "\n",
        "4. Following are model parameters/coefficients =  [-2.60429857e+04  1.66021982e+06 -4.55463186e+07  7.25884218e+08\n",
        " -7.60880085e+09  5.60762719e+10 -3.02274990e+11  1.21971777e+12\n",
        " -3.72536198e+12  8.60617788e+12 -1.47811533e+13  1.79179180e+13\n",
        " -1.28403376e+13 -3.02767157e+11  1.35419924e+13 -1.81116496e+13\n",
        "  1.34368586e+13 -6.14438987e+12  1.62920191e+12 -1.93081499e+11]\n",
        "\n",
        "**4.2. What conclusion can you draw from the training and the testing MSE?**\n",
        "\n",
        "**Answer:**\n",
        "1.  L2 - MSE train =  8.037539242127623e-07\n",
        "    \n",
        "    L2 - MSE test =  8.037539242127623e-07\n",
        "\n",
        "\n",
        "2. Training and testing  MSE gives the same values for the given data using Linear Regression Model\n",
        "\n",
        "3.  The value is low which helps to eliminate the overfitting of the model.\n",
        "\n",
        "\n",
        "**4.3. Is the linear regression model better than the previous two lasso models? From all the three models which one would you prefer and why?**\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "1. Yes,  the linear regression model is better than the previous two lasso models.\n",
        "\n",
        "\n",
        "2. From all three models Linear Regression model gives the lowest value of mean square error so, it will help to minimize the overfitting. For that reason I like to select the Linear Regression Model.\n"
      ],
      "metadata": {
        "id": "z5i-Tx4QZt0j"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}